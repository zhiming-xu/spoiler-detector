{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Sequence to Sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:14:50.359769Z",
     "start_time": "2019-04-22T03:14:49.467928Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import time\n",
    "from mxnet import nd, init, gluon, autograd\n",
    "from mxnet.gluon import nn, rnn, loss as gloss\n",
    "import d2l\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class TwoSeqEncoder(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(TwoSeqEncoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = rnn.LSTM(num_hiddens, num_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, *args):\n",
    "        left_input, right_input = X[0], X[1]\n",
    "        X_left = self.embedding(left_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_left = X_left.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        left_state = self.rnn.begin_state(batch_size=X_left.shape[1], \\\n",
    "                                               ctx=X_left.context)\n",
    "        left_out, left_state = self.rnn(X_left, left_state)\n",
    "        \n",
    "        X_right = self.embedding(right_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_right = X_right.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        right_state = self.rnn.begin_state(batch_size=X_right.shape[1], \\\n",
    "                                               ctx=X_right.context)\n",
    "        right_out, right_state = self.rnn(X_right, right_state)\n",
    "        # The shape of out is (seq_len, batch_size, num_hiddens).\n",
    "        # state contains the hidden state and the memory cell\n",
    "        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)\n",
    "        return left_out[-1][:][:], right_out[-1][:][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[-2.2143868e-04  3.5002387e-05  2.7029600e-04  2.8731427e-05\n",
       "   -5.2404794e-05  1.4110740e-05 -2.0850824e-04  1.0625856e-04\n",
       "    1.5787718e-04  1.1166865e-04 -3.7516581e-04  1.7297745e-04\n",
       "   -6.5742475e-05  6.8289250e-05 -2.2307977e-04 -5.6489898e-05]\n",
       "  [-2.2143868e-04  3.5002387e-05  2.7029600e-04  2.8731427e-05\n",
       "   -5.2404794e-05  1.4110740e-05 -2.0850824e-04  1.0625856e-04\n",
       "    1.5787718e-04  1.1166865e-04 -3.7516581e-04  1.7297745e-04\n",
       "   -6.5742475e-05  6.8289250e-05 -2.2307977e-04 -5.6489898e-05]\n",
       "  [-2.2143868e-04  3.5002387e-05  2.7029600e-04  2.8731427e-05\n",
       "   -5.2404794e-05  1.4110740e-05 -2.0850824e-04  1.0625856e-04\n",
       "    1.5787718e-04  1.1166865e-04 -3.7516581e-04  1.7297745e-04\n",
       "   -6.5742475e-05  6.8289250e-05 -2.2307977e-04 -5.6489898e-05]\n",
       "  [-2.2143868e-04  3.5002387e-05  2.7029600e-04  2.8731427e-05\n",
       "   -5.2404794e-05  1.4110740e-05 -2.0850824e-04  1.0625856e-04\n",
       "    1.5787718e-04  1.1166865e-04 -3.7516581e-04  1.7297745e-04\n",
       "   -6.5742475e-05  6.8289250e-05 -2.2307977e-04 -5.6489898e-05]]\n",
       " <NDArray 4x16 @cpu(0)>, \n",
       " [[-2.60586694e-05 -7.48698367e-05  1.07375789e-04 -1.87350131e-04\n",
       "   -1.13413116e-04  3.63644649e-04 -3.87638516e-04 -9.70876645e-05\n",
       "    8.98165599e-05 -3.05409223e-04 -7.73195061e-05  5.32191916e-05\n",
       "   -1.59329920e-05  4.66993079e-05  4.30881737e-05  1.13482580e-04]\n",
       "  [-2.60586694e-05 -7.48698367e-05  1.07375789e-04 -1.87350131e-04\n",
       "   -1.13413116e-04  3.63644649e-04 -3.87638516e-04 -9.70876645e-05\n",
       "    8.98165599e-05 -3.05409223e-04 -7.73195061e-05  5.32191916e-05\n",
       "   -1.59329920e-05  4.66993079e-05  4.30881737e-05  1.13482580e-04]\n",
       "  [-2.60586694e-05 -7.48698367e-05  1.07375789e-04 -1.87350131e-04\n",
       "   -1.13413116e-04  3.63644649e-04 -3.87638516e-04 -9.70876645e-05\n",
       "    8.98165599e-05 -3.05409223e-04 -7.73195061e-05  5.32191916e-05\n",
       "   -1.59329920e-05  4.66993079e-05  4.30881737e-05  1.13482580e-04]\n",
       "  [-2.60586694e-05 -7.48698367e-05  1.07375789e-04 -1.87350131e-04\n",
       "   -1.13413116e-04  3.63644649e-04 -3.87638516e-04 -9.70876645e-05\n",
       "    8.98165599e-05 -3.05409223e-04 -7.73195061e-05  5.32191916e-05\n",
       "   -1.59329920e-05  4.66993079e-05  4.30881737e-05  1.13482580e-04]]\n",
       " <NDArray 4x16 @cpu(0)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TwoSeqEncoder(vocab_size=10, embed_size=8,\n",
    "                         num_hiddens=16, num_layers=2)\n",
    "encoder.initialize()\n",
    "X = nd.zeros((4, 7))\n",
    "Y = nd.ones((4, 10))\n",
    "left_output, right_output = encoder([X, Y])\n",
    "# after running the encoder, output and state are both a list\n",
    "# which contains the whole output and state of each time state in history\n",
    "left_output, right_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_neg_abs_sim(left_embed, right_embed):\n",
    "    return nd.exp(-nd.sum(nd.abs(left_embed-right_embed), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManhattanDistance = nn.Lambda(lambda x: exp_neg_abs_sim(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.9971166]\n",
       " [0.9971166]\n",
       " [0.9971166]\n",
       " [0.9971166]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ManhattanDistance([left_output, right_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "This part is alike that in keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): TwoSeqEncoder(\n",
      "    (embedding): Embedding(1000 -> 16, float32)\n",
      "    (rnn): LSTM(None -> 32, TNC, num_layers=16)\n",
      "  )\n",
      "  (1): Lambda(<lambda>)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1.]\n",
       " [1.]\n",
       " [1.]\n",
       " [1.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add(TwoSeqEncoder(vocab_size=1000, embed_size=16, num_hiddens=32, num_layers=16),\\\n",
    "          ManhattanDistance)\n",
    "model.initialize()\n",
    "print(model)\n",
    "model([X, Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch7(model, data_iter, lr, num_epochs, ctx):  # Saved in d2l\n",
    "    model.initialize(init.Xavier(), force_reinit=True, ctx=ctx)\n",
    "    trainer = gluon.Trainer(model.collect_params(),\n",
    "                            'adam', {'learning_rate': lr})\n",
    "    loss = gloss.L1Loss\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        l_sum = 0.0\n",
    "        for batch in data_iter:\n",
    "            left, right, label = [x.as_in_context(ctx) for x in batch]\n",
    "            with autograd.record():\n",
    "                predict = model([left, right])\n",
    "                l = loss(predict, label)\n",
    "            l.backward()\n",
    "            l_sum += l\n",
    "            d2l.grad_clipping_gluon(model, 5, ctx)\n",
    "            trainer.step(1)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"epoch %d, loss %.3f, time %.1f sec\" % (\n",
    "                epoch, l_sum, time.time()-tic))\n",
    "            tic = time.time()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>plot_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>tt2404463</td>\n",
       "      <td>Terrible How can you watch this the whole way ...</td>\n",
       "      <td>Sarah Ashburn, an FBI agent, is extremely ambi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>tt0878804</td>\n",
       "      <td>A  feel good movie without the mush.. I went t...</td>\n",
       "      <td>Based on the true story of Leigh Anne Tuohy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>tt0116191</td>\n",
       "      <td>Woefully bad Reading through all these positiv...</td>\n",
       "      <td>Emma Woodhouse is a congenial young lady who d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0773262</td>\n",
       "      <td>This show is a serial killer..! All right, set...</td>\n",
       "      <td>Dexter Morgan, Miami Metro Police Department b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>tt2226597</td>\n",
       "      <td>Like Any \"Mountain\", It Just Feels Unmovable S...</td>\n",
       "      <td>Stranded after a tragic plane crash, two stran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spoiler   movie_id                                        review_text  \\\n",
       "0       False  tt2404463  Terrible How can you watch this the whole way ...   \n",
       "1       False  tt0878804  A  feel good movie without the mush.. I went t...   \n",
       "2       False  tt0116191  Woefully bad Reading through all these positiv...   \n",
       "3        True  tt0773262  This show is a serial killer..! All right, set...   \n",
       "4       False  tt2226597  Like Any \"Mountain\", It Just Feels Unmovable S...   \n",
       "\n",
       "                                        plot_summary  \n",
       "0  Sarah Ashburn, an FBI agent, is extremely ambi...  \n",
       "1  Based on the true story of Leigh Anne Tuohy an...  \n",
       "2  Emma Woodhouse is a congenial young lady who d...  \n",
       "3  Dexter Morgan, Miami Metro Police Department b...  \n",
       "4  Stranded after a tragic plane crash, two stran...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_examples, max_len = 64, 1e3, 10\n",
    "lr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()\n",
    "# load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [],
   "source": [
    "def translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, ctx):\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')]\n",
    "    src_len = len(src_tokens)\n",
    "    if src_len < max_len:\n",
    "        src_tokens += [src_vocab.pad] * (max_len - src_len)\n",
    "    enc_X = nd.array(src_tokens, ctx=ctx)\n",
    "    enc_valid_length = nd.array([src_len], ctx=ctx)\n",
    "    # use expand_dim to add the batch_size dimension.\n",
    "    enc_outputs = model.encoder(enc_X.expand_dims(axis=0), enc_valid_length)\n",
    "    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n",
    "    dec_X = nd.array([tgt_vocab.bos], ctx=ctx).expand_dims(axis=0)\n",
    "    predict_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        Y, dec_state = model.decoder(dec_X, dec_state)\n",
    "        # The token with highest score is used as the next time step input. \n",
    "        dec_X = Y.argmax(axis=2)\n",
    "        py = dec_X.squeeze(axis=0).astype('int32').asscalar()\n",
    "        if py == tgt_vocab.eos:\n",
    "            break\n",
    "        predict_tokens.append(py)\n",
    "    return ' '.join(tgt_vocab.to_tokens(predict_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try several examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Wow ! => <unk> !\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emportÃ© !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + translate_ch7(\n",
    "        model, sentence, src_vocab, tgt_vocab, max_len, ctx))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
