{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Sequence to Sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:14:50.359769Z",
     "start_time": "2019-04-22T03:14:49.467928Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import time\n",
    "from mxnet import nd, init, gluon, autograd\n",
    "from mxnet.gluon import nn, rnn, loss as gloss\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class TwoSeqEncoder(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(TwoSeqEncoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = rnn.LSTM(num_hiddens, num_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, left_input, right_input):\n",
    "        print('in encoder')\n",
    "        X_left = self.embedding(left_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_left = X_left.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        left_state = self.rnn.begin_state(batch_size=X_left.shape[1], \\\n",
    "                                               ctx=X_left.context)\n",
    "        left_out, _ = self.rnn(X_left, left_state)\n",
    "        \n",
    "        X_right = self.embedding(right_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_right = X_right.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        right_state = self.rnn.begin_state(batch_size=X_right.shape[1], \\\n",
    "                                               ctx=X_right.context)\n",
    "        right_out, _ = self.rnn(X_right, right_state)\n",
    "        # The shape of out is (seq_len, batch_size, num_hiddens).\n",
    "        # state contains the hidden state and the memory cell\n",
    "        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)\n",
    "        return left_out[:][-1][:], right_out[:][-1][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in encoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[-9.3526716e-05 -4.9678278e-05  1.4228432e-05 -1.6644204e-04\n",
       "    9.7964104e-05 -1.9300998e-04  1.5927634e-04 -2.7911537e-05\n",
       "    1.8589392e-04 -7.2337089e-06 -3.2081801e-04 -1.8444611e-05\n",
       "   -1.9077418e-04 -1.6275543e-04 -1.9651403e-05 -5.4234817e-05]\n",
       "  [-9.3526716e-05 -4.9678278e-05  1.4228432e-05 -1.6644204e-04\n",
       "    9.7964104e-05 -1.9300998e-04  1.5927634e-04 -2.7911537e-05\n",
       "    1.8589392e-04 -7.2337089e-06 -3.2081801e-04 -1.8444611e-05\n",
       "   -1.9077418e-04 -1.6275543e-04 -1.9651403e-05 -5.4234817e-05]\n",
       "  [-9.3526716e-05 -4.9678278e-05  1.4228432e-05 -1.6644204e-04\n",
       "    9.7964104e-05 -1.9300998e-04  1.5927634e-04 -2.7911537e-05\n",
       "    1.8589392e-04 -7.2337089e-06 -3.2081801e-04 -1.8444611e-05\n",
       "   -1.9077418e-04 -1.6275543e-04 -1.9651403e-05 -5.4234817e-05]\n",
       "  [-9.3526716e-05 -4.9678278e-05  1.4228432e-05 -1.6644204e-04\n",
       "    9.7964104e-05 -1.9300998e-04  1.5927634e-04 -2.7911537e-05\n",
       "    1.8589392e-04 -7.2337089e-06 -3.2081801e-04 -1.8444611e-05\n",
       "   -1.9077418e-04 -1.6275543e-04 -1.9651403e-05 -5.4234817e-05]]\n",
       " <NDArray 4x16 @cpu(0)>, \n",
       " [[-2.6243614e-04  1.8116225e-04  3.0691397e-05 -1.7932788e-04\n",
       "    1.9677175e-04 -4.0638287e-04 -1.2812782e-04  2.4706309e-04\n",
       "    1.3254523e-04  3.1308370e-04  1.3571592e-04 -3.8519321e-04\n",
       "   -3.3583379e-04  1.8453244e-04  2.6650197e-04 -3.7035818e-04]\n",
       "  [-2.6243614e-04  1.8116225e-04  3.0691397e-05 -1.7932788e-04\n",
       "    1.9677175e-04 -4.0638287e-04 -1.2812782e-04  2.4706309e-04\n",
       "    1.3254523e-04  3.1308370e-04  1.3571592e-04 -3.8519321e-04\n",
       "   -3.3583379e-04  1.8453244e-04  2.6650197e-04 -3.7035818e-04]\n",
       "  [-2.6243614e-04  1.8116225e-04  3.0691397e-05 -1.7932788e-04\n",
       "    1.9677175e-04 -4.0638287e-04 -1.2812782e-04  2.4706309e-04\n",
       "    1.3254523e-04  3.1308370e-04  1.3571592e-04 -3.8519321e-04\n",
       "   -3.3583379e-04  1.8453244e-04  2.6650197e-04 -3.7035818e-04]\n",
       "  [-2.6243614e-04  1.8116225e-04  3.0691397e-05 -1.7932788e-04\n",
       "    1.9677175e-04 -4.0638287e-04 -1.2812782e-04  2.4706309e-04\n",
       "    1.3254523e-04  3.1308370e-04  1.3571592e-04 -3.8519321e-04\n",
       "   -3.3583379e-04  1.8453244e-04  2.6650197e-04 -3.7035818e-04]]\n",
       " <NDArray 4x16 @cpu(0)>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TwoSeqEncoder(vocab_size=10, embed_size=8,\n",
    "                         num_hiddens=16, num_layers=2)\n",
    "encoder.initialize()\n",
    "X = nd.zeros((4, 7))\n",
    "Y = nd.ones((4, 10))\n",
    "left_output, right_output = encoder(X, Y)\n",
    "# after running the encoder, output and state are both a list\n",
    "# which contains the whole output and state of each time state in history\n",
    "left_output, right_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_neg_abs_sim(left_embed, right_embed):\n",
    "    return nd.exp(-nd.sum(nd.abs(left_embed-right_embed), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManhattanDistance = nn.Lambda(lambda x: exp_neg_abs_sim(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.99716175]\n",
       " [0.99716175]\n",
       " [0.99716175]\n",
       " [0.99716175]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ManhattanDistance([left_output, right_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): TwoSeqEncoder(\n",
      "    (embedding): Embedding(2 -> 10, float32)\n",
      "    (rnn): LSTM(None -> 32, TNC, num_layers=16)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-e391240db854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add(TwoSeqEncoder(vocab_size=2, embed_size=10, num_hiddens=32, num_layers=16))\n",
    "model.initialize()\n",
    "print(model)\n",
    "model(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch7(model, data_iter, lr, num_epochs, ctx):  # Saved in d2l\n",
    "    model.initialize(init.Xavier(), force_reinit=True, ctx=ctx)\n",
    "    trainer = gluon.Trainer(model.collect_params(),\n",
    "                            'adam', {'learning_rate': lr})\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        l_sum, num_tokens_sum = 0.0, 0.0\n",
    "        for batch in data_iter:\n",
    "            X, X_vlen, Y, Y_vlen = [x.as_in_context(ctx) for x in batch]\n",
    "            Y_input, Y_label, Y_vlen = Y[:,:-1], Y[:,1:], Y_vlen-1\n",
    "            with autograd.record():\n",
    "                Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)\n",
    "                l = loss(Y_hat, Y_label, Y_vlen)\n",
    "            l.backward()\n",
    "            d2l.grad_clipping_gluon(model, 5, ctx)\n",
    "            num_tokens = Y_vlen.sum().asscalar()\n",
    "            trainer.step(num_tokens)\n",
    "            l_sum += l.sum().asscalar()\n",
    "            num_tokens_sum += num_tokens\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"epoch %d, loss %.3f, time %.1f sec\" % (\n",
    "                epoch, l_sum/num_tokens_sum, time.time()-tic))\n",
    "            tic = time.time()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 0.120, time 10.2 sec\n",
      "epoch 100, loss 0.066, time 10.4 sec\n",
      "epoch 150, loss 0.041, time 10.3 sec\n",
      "epoch 200, loss 0.031, time 10.3 sec\n",
      "epoch 250, loss 0.028, time 10.0 sec\n",
      "epoch 300, loss 0.025, time 9.5 sec\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_examples, max_len = 64, 1e3, 10\n",
    "lr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(\n",
    "    batch_size, max_len, num_examples)\n",
    "encoder = Seq2SeqEncoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqDecoder(\n",
    "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = d2l.EncoderDecoder(encoder, decoder)\n",
    "train_ch7(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [],
   "source": [
    "def translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, ctx):\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')]\n",
    "    src_len = len(src_tokens)\n",
    "    if src_len < max_len:\n",
    "        src_tokens += [src_vocab.pad] * (max_len - src_len)\n",
    "    enc_X = nd.array(src_tokens, ctx=ctx)\n",
    "    enc_valid_length = nd.array([src_len], ctx=ctx)\n",
    "    # use expand_dim to add the batch_size dimension.\n",
    "    enc_outputs = model.encoder(enc_X.expand_dims(axis=0), enc_valid_length)\n",
    "    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n",
    "    dec_X = nd.array([tgt_vocab.bos], ctx=ctx).expand_dims(axis=0)\n",
    "    predict_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        Y, dec_state = model.decoder(dec_X, dec_state)\n",
    "        # The token with highest score is used as the next time step input. \n",
    "        dec_X = Y.argmax(axis=2)\n",
    "        py = dec_X.squeeze(axis=0).astype('int32').asscalar()\n",
    "        if py == tgt_vocab.eos:\n",
    "            break\n",
    "        predict_tokens.append(py)\n",
    "    return ' '.join(tgt_vocab.to_tokens(predict_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try several examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Wow ! => <unk> !\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emportÃ© !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + translate_ch7(\n",
    "        model, sentence, src_vocab, tgt_vocab, max_len, ctx))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
